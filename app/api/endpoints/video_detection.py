# app/api/endpoints/video_detection.py
from fastapi import APIRouter, HTTPException, File, UploadFile, Form, BackgroundTasks, Depends, Request
from fastapi.responses import JSONResponse, FileResponse
import cv2
import numpy as np
import tempfile
import os
import uuid
import logging
import asyncio
from typing import Optional, Dict, List, Any
from datetime import datetime, timedelta
from pathlib import Path
import json

from app.schemas.detection import DetectionResponse, LostObjectAlert
from app.utils.image_utils import validate_image, get_image_info
from app.core.model_manager import ModelManager
from app.config.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)

# Stockage des t√¢ches de traitement vid√©o
video_tasks: Dict[str, Dict] = {}

class VideoProcessor:
    """Processeur de vid√©o pour la d√©tection"""
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
        self.temp_dir = settings.TEMP_DIR
    
    async def process_video(self, video_path: Path, task_id: str, **kwargs):
        """Traite une vid√©o compl√®te"""
        try:
            # Mise √† jour du statut
            video_tasks[task_id]['status'] = 'processing'
            video_tasks[task_id]['started_at'] = datetime.now()
            
            # Ouverture de la vid√©o
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                raise ValueError("Impossible d'ouvrir la vid√©o")
            
            # Informations vid√©o
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            video_tasks[task_id].update({
                'total_frames': total_frames,
                'fps': fps,
                'duration': duration,
                'resolution': (width, height),
                'processed_frames': 0
            })
            
            # Param√®tres de traitement
            model_name = kwargs.get('model_name', 'stable_epoch_30')
            confidence_threshold = kwargs.get('confidence_threshold', 0.5)
            frame_skip = kwargs.get('frame_skip', 1)  # Traiter 1 frame sur N
            max_frames = kwargs.get('max_frames', None)
            
            # R√©cup√©ration du d√©tecteur
            detector = await self.model_manager.get_detector(model_name)
            
            # R√©sultats de traitement
            detections_timeline = []
            alerts_timeline = []
            frame_count = 0
            processed_count = 0
            
            logger.info(f"Traitement vid√©o {task_id}: {total_frames} frames, {fps:.1f} FPS")
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                # Skip frames si n√©cessaire
                if frame_count % frame_skip != 0:
                    continue
                
                # Limite de frames si sp√©cifi√©e
                if max_frames and processed_count >= max_frames:
                    break
                
                # Validation de la frame
                if not validate_image(frame):
                    continue
                
                try:
                    # D√©tection sur cette frame
                    objects, persons, alerts = detector.detect(
                        frame,
                        confidence_threshold=confidence_threshold,
                        enable_tracking=True,
                        enable_lost_detection=True
                    )
                    
                    # Timestamp de la frame
                    timestamp = frame_count / fps if fps > 0 else processed_count
                    
                    # Stockage des r√©sultats
                    frame_result = {
                        'frame_number': frame_count,
                        'timestamp': timestamp,
                        'objects_count': len(objects),
                        'persons_count': len(persons),
                        'objects': [self._serialize_object(obj) for obj in objects],
                        'persons': [self._serialize_person(person) for person in persons]
                    }
                    detections_timeline.append(frame_result)
                    
                    # Alertes
                    for alert in alerts:
                        alert_data = alert.dict()
                        alert_data['frame_number'] = frame_count
                        alert_data['timestamp'] = timestamp
                        alerts_timeline.append(alert_data)
                    
                    processed_count += 1
                    
                    # Mise √† jour du progr√®s
                    video_tasks[task_id]['processed_frames'] = processed_count
                    video_tasks[task_id]['progress'] = (frame_count / total_frames) * 100
                    
                    # Log p√©riodique
                    if processed_count % 100 == 0:
                        logger.info(f"Vid√©o {task_id}: {processed_count} frames trait√©es "
                                  f"({video_tasks[task_id]['progress']:.1f}%)")
                
                except Exception as e:
                    logger.error(f"Erreur traitement frame {frame_count}: {e}")
                    continue
            
            # Fermeture
            cap.release()
            
            # G√©n√©ration du rapport final
            report = self._generate_video_report(
                detections_timeline, alerts_timeline, video_tasks[task_id]
            )
            
            # Sauvegarde du rapport
            report_path = self.temp_dir / f"report_{task_id}.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            # Finalisation
            video_tasks[task_id].update({
                'status': 'completed',
                'completed_at': datetime.now(),
                'report_path': str(report_path),
                'detections_count': len(detections_timeline),
                'alerts_count': len(alerts_timeline),
                'report': report
            })
            
            logger.info(f"Vid√©o {task_id} trait√©e: {processed_count} frames, "
                       f"{len(alerts_timeline)} alertes")
            
        except Exception as e:
            logger.error(f"Erreur traitement vid√©o {task_id}: {e}")
            video_tasks[task_id].update({
                'status': 'error',
                'error': str(e),
                'completed_at': datetime.now()
            })
            raise
        
        finally:
            # Nettoyage du fichier temporaire
            try:
                if video_path.exists():
                    os.unlink(video_path)
            except Exception as e:
                logger.warning(f"Impossible de supprimer {video_path}: {e}")
    
    def _serialize_object(self, obj) -> dict:
        """S√©rialise un objet pour JSON"""
        return {
            'object_id': obj.object_id,
            'class_name': obj.class_name,
            'class_name_fr': obj.class_name_fr,
            'confidence': obj.confidence,
            'bounding_box': {
                'x': obj.bounding_box.x,
                'y': obj.bounding_box.y,
                'width': obj.bounding_box.width,
                'height': obj.bounding_box.height
            },
            'status': obj.status.value,
            'duration_stationary': obj.duration_stationary
        }
    
    def _serialize_person(self, person) -> dict:
        """S√©rialise une personne pour JSON"""
        return {
            'person_id': person.person_id,
            'confidence': person.confidence,
            'bounding_box': {
                'x': person.bounding_box.x,
                'y': person.bounding_box.y,
                'width': person.bounding_box.width,
                'height': person.bounding_box.height
            },
            'position': person.position
        }
    
    def _generate_video_report(self, detections: List, alerts: List, task_info: dict) -> dict:
        """G√©n√®re un rapport de traitement vid√©o"""
        # Statistiques globales
        total_objects = sum(frame['objects_count'] for frame in detections)
        total_persons = sum(frame['persons_count'] for frame in detections)
        
        # Analyse temporelle des objets perdus
        lost_objects_over_time = []
        for frame in detections:
            lost_count = sum(1 for obj in frame['objects'] 
                           if obj['status'] in ['lost', 'critical'])
            lost_objects_over_time.append({
                'timestamp': frame['timestamp'],
                'frame_number': frame['frame_number'],
                'lost_objects': lost_count
            })
        
        # Distribution des classes d'objets
        class_distribution = {}
        for frame in detections:
            for obj in frame['objects']:
                class_name = obj['class_name_fr']
                class_distribution[class_name] = class_distribution.get(class_name, 0) + 1
        
        # Alertes par p√©riode
        alerts_by_minute = {}
        for alert in alerts:
            minute = int(alert['timestamp'] // 60)
            alerts_by_minute[minute] = alerts_by_minute.get(minute, 0) + 1
        
        # P√©riodes critiques (> 2 alertes par minute)
        critical_periods = [
            {'minute': minute, 'alerts_count': count}
            for minute, count in alerts_by_minute.items()
            if count > 2
        ]
        
        return {
            'task_info': {
                'task_id': task_info['task_id'],
                'video_duration': task_info['duration'],
                'total_frames': task_info['total_frames'],
                'processed_frames': task_info['processed_frames'],
                'fps': task_info['fps'],
                'resolution': task_info['resolution'],
                'processing_time': (task_info.get('completed_at', datetime.now()) - 
                                  task_info.get('started_at', datetime.now())).total_seconds()
            },
            'statistics': {
                'total_detections': len(detections),
                'total_objects': total_objects,
                'total_persons': total_persons,
                'total_alerts': len(alerts),
                'avg_objects_per_frame': total_objects / len(detections) if detections else 0,
                'avg_persons_per_frame': total_persons / len(detections) if detections else 0
            },
            'class_distribution': class_distribution,
            'lost_objects_timeline': lost_objects_over_time,
            'alerts_timeline': alerts,
            'critical_periods': critical_periods,
            'recommendations': self._generate_recommendations(
                detections, alerts, class_distribution
            )
        }
    
    def _generate_recommendations(self, detections: List, alerts: List, 
                                class_distribution: dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse"""
        recommendations = []
        
        if len(alerts) > 10:
            recommendations.append("üö® Nombre √©lev√© d'alertes d√©tect√© - v√©rifier la configuration des seuils")
        
        if len(detections) > 0:
            avg_objects = sum(f['objects_count'] for f in detections) / len(detections)
            if avg_objects > 10:
                recommendations.append("üì¶ Sc√®ne dense d√©tect√©e - consid√©rer l'optimisation des param√®tres NMS")
        
        # Top objets perdus
        top_lost_classes = sorted(class_distribution.items(), key=lambda x: x[1], reverse=True)[:3]
        if top_lost_classes:
            top_class = top_lost_classes[0][0]
            recommendations.append(f"üìä Objet le plus fr√©quent: {top_class} - surveillance renforc√©e recommand√©e")
        
        if not recommendations:
            recommendations.append("‚úÖ Aucune anomalie d√©tect√©e - surveillance normale")
        
        return recommendations

async def get_model_manager(request: Request) -> ModelManager:
    """R√©cup√®re le gestionnaire de mod√®les"""
    return request.app.state.model_manager

@router.post("/video")
async def detect_objects_in_video(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    model_name: Optional[str] = Form("stable_epoch_30"),
    confidence_threshold: Optional[float] = Form(0.5),
    frame_skip: Optional[int] = Form(1),
    max_frames: Optional[int] = Form(None),
    model_manager: ModelManager = Depends(get_model_manager)
):
    """
    üé¨ Lance le traitement d'une vid√©o pour d√©tecter les objets perdus
    
    **Param√®tres:**
    - file: Fichier vid√©o (MP4, AVI, MOV, etc.)
    - model_name: Mod√®le √† utiliser pour la d√©tection
    - confidence_threshold: Seuil de confiance (0.0-1.0)
    - frame_skip: Traiter 1 frame sur N (1=toutes, 2=une sur deux, etc.)
    - max_frames: Limite du nombre de frames √† traiter
    
    **Retour:**
    - task_id: ID de la t√¢che pour suivre le progr√®s
    - status_url: URL pour suivre l'avancement
    """
    
    try:
        # Validation du fichier
        if not file.content_type.startswith('video/'):
            raise HTTPException(
                status_code=400,
                detail=f"Type de fichier non support√©: {file.content_type}. "
                       f"Formats support√©s: MP4, AVI, MOV, MKV"
            )
        
        # Validation des param√®tres
        if not (0.0 <= confidence_threshold <= 1.0):
            raise HTTPException(
                status_code=400,
                detail="confidence_threshold doit √™tre entre 0.0 et 1.0"
            )
        
        if frame_skip < 1:
            raise HTTPException(
                status_code=400,
                detail="frame_skip doit √™tre >= 1"
            )
        
        if max_frames is not None and max_frames < 1:
            raise HTTPException(
                status_code=400,
                detail="max_frames doit √™tre >= 1"
            )
        
        # G√©n√©ration de l'ID de t√¢che
        task_id = str(uuid.uuid4())
        
        # Sauvegarde temporaire du fichier
        temp_path = settings.TEMP_DIR / f"video_{task_id}_{file.filename}"
        
        try:
            with open(temp_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Erreur sauvegarde fichier: {str(e)}"
            )
        
        # Validation basique de la vid√©o
        cap = cv2.VideoCapture(str(temp_path))
        if not cap.isOpened():
            os.unlink(temp_path)
            raise HTTPException(
                status_code=400,
                detail="Fichier vid√©o invalide ou corrompu"
            )
        
        # Informations basiques
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        duration = total_frames / fps if fps > 0 else 0
        cap.release()
        
        # V√©rification des limites
        if duration > 1800:  # 30 minutes max
            os.unlink(temp_path)
            raise HTTPException(
                status_code=400,
                detail=f"Vid√©o trop longue: {duration/60:.1f} min. Maximum: 30 min"
            )
        
        # Cr√©ation de la t√¢che
        video_tasks[task_id] = {
            'task_id': task_id,
            'filename': file.filename,
            'status': 'queued',
            'created_at': datetime.now(),
            'total_frames': total_frames,
            'fps': fps,
            'duration': duration,
            'progress': 0,
            'model_name': model_name,
            'confidence_threshold': confidence_threshold,
            'frame_skip': frame_skip,
            'max_frames': max_frames
        }
        
        # Lancement du traitement en arri√®re-plan
        processor = VideoProcessor(model_manager)
        background_tasks.add_task(
            processor.process_video,
            temp_path,
            task_id,
            model_name=model_name,
            confidence_threshold=confidence_threshold,
            frame_skip=frame_skip,
            max_frames=max_frames
        )
        
        logger.info(f"T√¢che vid√©o lanc√©e: {task_id} ({file.filename}, {duration:.1f}s)")
        
        return {
            "success": True,
            "task_id": task_id,
            "message": f"Traitement vid√©o lanc√© pour {file.filename}",
            "estimated_duration": f"{duration:.1f} secondes",
            "total_frames": total_frames,
            "status_url": f"/api/v1/detect/video/status/{task_id}",
            "download_url": f"/api/v1/detect/video/report/{task_id}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur traitement vid√©o: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur interne: {str(e)}"
        )

@router.get("/video/status/{task_id}")
async def get_video_task_status(task_id: str):
    """
    üìä R√©cup√®re le statut d'une t√¢che de traitement vid√©o
    
    **√âtats possibles:**
    - queued: En attente de traitement
    - processing: En cours de traitement
    - completed: Termin√© avec succ√®s
    - error: Erreur lors du traitement
    """
    
    if task_id not in video_tasks:
        raise HTTPException(
            status_code=404,
            detail=f"T√¢che {task_id} non trouv√©e"
        )
    
    task = video_tasks[task_id]
    
    # Calcul du temps √©coul√©
    now = datetime.now()
    elapsed = (now - task['created_at']).total_seconds()
    
    # Estimation du temps restant
    eta = None
    if task['status'] == 'processing' and task.get('progress', 0) > 0:
        progress_ratio = task['progress'] / 100
        estimated_total = elapsed / progress_ratio
        eta = max(0, estimated_total - elapsed)
    
    response = {
        "task_id": task_id,
        "status": task['status'],
        "progress": task.get('progress', 0),
        "created_at": task['created_at'].isoformat(),
        "elapsed_seconds": elapsed,
        "estimated_remaining_seconds": eta,
        "filename": task['filename'],
        "total_frames": task.get('total_frames', 0),
        "processed_frames": task.get('processed_frames', 0)
    }
    
    # Informations additionnelles selon le statut
    if task['status'] == 'completed':
        response.update({
            "completed_at": task.get('completed_at', '').isoformat() if task.get('completed_at') else '',
            "detections_count": task.get('detections_count', 0),
            "alerts_count": task.get('alerts_count', 0),
            "report_available": True
        })
    
    elif task['status'] == 'error':
        response.update({
            "error": task.get('error', 'Erreur inconnue'),
            "completed_at": task.get('completed_at', '').isoformat() if task.get('completed_at') else ''
        })
    
    return response

@router.get("/video/report/{task_id}")
async def download_video_report(task_id: str):
    """
    üì• T√©l√©charge le rapport de traitement vid√©o
    
    Retourne un fichier JSON contenant:
    - Timeline des d√©tections
    - Alertes g√©n√©r√©es
    - Statistiques globales
    - Recommandations
    """
    
    if task_id not in video_tasks:
        raise HTTPException(
            status_code=404,
            detail=f"T√¢che {task_id} non trouv√©e"
        )
    
    task = video_tasks[task_id]
    
    if task['status'] != 'completed':
        raise HTTPException(
            status_code=400,
            detail=f"T√¢che pas encore termin√©e (statut: {task['status']})"
        )
    
    report_path = task.get('report_path')
    if not report_path or not Path(report_path).exists():
        raise HTTPException(
            status_code=404,
            detail="Rapport non disponible"
        )
    
    return FileResponse(
        path=report_path,
        filename=f"video_report_{task_id}.json",
        media_type="application/json"
    )

@router.get("/video/tasks")
async def list_video_tasks(limit: int = 50, status: Optional[str] = None):
    """
    üìã Liste les t√¢ches de traitement vid√©o
    
    **Param√®tres:**
    - limit: Nombre maximum de t√¢ches √† retourner
    - status: Filtrer par statut (queued, processing, completed, error)
    """
    
    tasks = list(video_tasks.values())
    
    # Filtrage par statut
    if status:
        tasks = [task for task in tasks if task['status'] == status]
    
    # Tri par date de cr√©ation (plus r√©cent en premier)
    tasks.sort(key=lambda x: x['created_at'], reverse=True)
    
    # Limitation
    tasks = tasks[:limit]
    
    # Formatage pour la r√©ponse
    formatted_tasks = []
    for task in tasks:
        formatted_task = {
            "task_id": task['task_id'],
            "filename": task['filename'],
            "status": task['status'],
            "progress": task.get('progress', 0),
            "created_at": task['created_at'].isoformat(),
            "duration": task.get('duration', 0)
        }
        
        if task['status'] == 'completed':
            formatted_task.update({
                "completed_at": task.get('completed_at', '').isoformat() if task.get('completed_at') else '',
                "alerts_count": task.get('alerts_count', 0)
            })
        
        formatted_tasks.append(formatted_task)
    
    return {
        "success": True,
        "total_tasks": len(video_tasks),
        "filtered_tasks": len(formatted_tasks),
        "tasks": formatted_tasks
    }

@router.delete("/video/task/{task_id}")
async def delete_video_task(task_id: str):
    """
    üóëÔ∏è Supprime une t√¢che de traitement vid√©o
    
    Nettoie les fichiers temporaires et supprime la t√¢che de la m√©moire
    """
    
    if task_id not in video_tasks:
        raise HTTPException(
            status_code=404,
            detail=f"T√¢che {task_id} non trouv√©e"
        )
    
    task = video_tasks[task_id]
    
    # Nettoyage des fichiers
    try:
        report_path = task.get('report_path')
        if report_path and Path(report_path).exists():
            os.unlink(report_path)
    except Exception as e:
        logger.warning(f"Impossible de supprimer le rapport {task_id}: {e}")
    
    # Suppression de la m√©moire
    del video_tasks[task_id]
    
    logger.info(f"T√¢che {task_id} supprim√©e")
    
    return {
        "success": True,
        "message": f"T√¢che {task_id} supprim√©e"
    }