# ğŸ” Service IA - DÃ©tection d'Objets Perdus

**Service intelligent de dÃ©tection et surveillance d'objets perdus en temps rÃ©el**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Vue d'ensemble

Ce service utilise l'intelligence artificielle pour dÃ©tecter et surveiller les objets perdus dans des espaces publics comme les aÃ©roports, gares, centres commerciaux, etc. Il combine la dÃ©tection d'objets en temps rÃ©el avec une logique mÃ©tier intelligente pour identifier les objets abandonnÃ©s et gÃ©nÃ©rer des alertes automatiques.

### âœ¨ FonctionnalitÃ©s principales

- **ğŸ–¼ï¸ DÃ©tection sur images** : Analyse d'images statiques
- **ğŸ¬ Traitement vidÃ©o** : Analyse complÃ¨te de fichiers vidÃ©o
- **ğŸ“¡ Streaming temps rÃ©el** : DÃ©tection en direct via WebSocket
- **ğŸ§  IA intelligente** : 28 classes d'objets avec logique d'objets perdus
- **âš¡ Performance optimisÃ©e** : Support GPU/CPU, cache intelligent
- **ğŸš¨ Alertes automatiques** : GÃ©nÃ©ration d'alertes contextuelles
- **ğŸ“Š Analytics** : Statistiques et tendances en temps rÃ©el

## ğŸ—ï¸ Architecture

```
ğŸ“ ai-service/
â”œâ”€â”€ ğŸ“ app/                          # ğŸ¯ CÅ’UR DE L'APPLICATION
â”‚   â”œâ”€â”€ ğŸ“„ main.py                   # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ ğŸ“ api/                      # ğŸŒ COUCHE API
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ routes.py             # Routes principales
â”‚   â”‚   â””â”€â”€ ğŸ“ endpoints/            # Endpoints spÃ©cialisÃ©s
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ image_detection.py    # ğŸ“¸ Images statiques
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ video_detection.py    # ğŸ¬ VidÃ©os
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ stream_detection.py   # ğŸ“¡ Streaming temps rÃ©el
â”‚   â”‚       â””â”€â”€ ğŸ“„ models.py             # ğŸ¤– Gestion modÃ¨les
â”‚   â”œâ”€â”€ ğŸ“ core/                     # ğŸ§  LOGIQUE MÃ‰TIER
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ detector.py           # DÃ©tecteur principal
â”‚   â”‚   â””â”€â”€ ğŸ“„ model_manager.py      # Gestionnaire modÃ¨les
â”‚   â”œâ”€â”€ ğŸ“ utils/                    # ğŸ”§ UTILITAIRES
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ image_utils.py        # Traitement images
â”‚   â”‚   â””â”€â”€ ğŸ“„ box_utils.py          # Manipulation bounding boxes
â”‚   â”œâ”€â”€ ğŸ“ services/                 # ğŸ¯ SERVICES MÃ‰TIER
â”‚   â”‚   â””â”€â”€ ğŸ“„ stream_service.py     # Service streaming
â”‚   â”œâ”€â”€ ğŸ“ schemas/                  # ğŸ“‹ SCHÃ‰MAS PYDANTIC
â”‚   â”‚   â””â”€â”€ ğŸ“„ detection.py          # SchÃ©mas dÃ©tection
â”‚   â””â”€â”€ ğŸ“ config/                   # âš™ï¸ CONFIGURATION
â”‚       â””â”€â”€ ğŸ“„ config.py             # Configuration gÃ©nÃ©rale
â”œâ”€â”€ ğŸ“ storage/                      # ğŸ’¾ STOCKAGE
â”‚   â”œâ”€â”€ ğŸ“ models/                   # ğŸ† MODÃˆLES ENTRAÃNÃ‰S
â”‚   â”œâ”€â”€ ğŸ“ temp/                     # Temporaire
â”‚   â””â”€â”€ ğŸ“ cache/                    # Cache modÃ¨les
â”œâ”€â”€ ğŸ“ tests/                        # ğŸ§ª TESTS
â”œâ”€â”€ ğŸ“ scripts/                      # ğŸ“œ SCRIPTS UTILITAIRES
â””â”€â”€ ğŸ“ logs/                         # ğŸ“‹ LOGS
```

## ğŸš€ Installation Rapide

### PrÃ©requis
- Python 3.8+
- 4GB RAM minimum (8GB recommandÃ©)
- GPU NVIDIA optionnel (pour de meilleures performances)

### 1. Clone et Installation

```bash
# Clone du projet
git clone <your-repo-url>
cd ai-service

# Installation automatique
python scripts/start_service.py --install
```

### 2. MÃ©thode Manuelle

```bash
# Installation des dÃ©pendances
pip install -r requirements.txt

# CrÃ©ation des rÃ©pertoires
mkdir -p storage/{models,temp,cache} logs

# Configuration
cp .env.example .env  # Puis Ã©ditez selon vos besoins

# DÃ©marrage
uvicorn app.main:app --reload
```

### 3. Docker (RecommandÃ©)

```bash
# Build et dÃ©marrage
docker-compose up -d

# Ou avec monitoring
docker-compose --profile monitoring up -d
```

## ğŸ® Utilisation

### ğŸ“± Interface Web

Une fois le service dÃ©marrÃ©, accÃ©dez Ã  :

- **API Documentation** : http://localhost:8000/docs
- **Interface Streaming** : http://localhost:8000/api/v1/stream/demo
- **Status SantÃ©** : http://localhost:8000/health

### ğŸ–¼ï¸ DÃ©tection d'Images

```python
import requests

# Upload d'un fichier
with open('image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/api/v1/detect/image',
        files={'file': f},
        data={
            'model_name': 'stable_epoch_30',
            'confidence_threshold': 0.5,
            'enable_lost_detection': True
        }
    )

result = response.json()
print(f"Objets dÃ©tectÃ©s: {result['total_objects']}")
print(f"Objets perdus: {result['lost_objects']}")
```

### ğŸ¬ Traitement VidÃ©o

```python
# Lancement du traitement
response = requests.post(
    'http://localhost:8000/api/v1/detect/video',
    files={'file': open('video.mp4', 'rb')},
    data={'frame_skip': 5, 'max_frames': 1000}
)

task_id = response.json()['task_id']

# Suivi du progrÃ¨s
status_response = requests.get(
    f'http://localhost:8000/api/v1/detect/video/status/{task_id}'
)

print(f"ProgrÃ¨s: {status_response.json()['progress']}%")
```

### ğŸ“¡ Streaming Temps RÃ©el

```python
import asyncio
import websockets
import json
import base64
import cv2

async def stream_webcam():
    uri = "ws://localhost:8000/api/v1/stream/ws/client_123"
    
    async with websockets.connect(uri) as websocket:
        cap = cv2.VideoCapture(0)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Encodage base64
            _, buffer = cv2.imencode('.jpg', frame)
            frame_b64 = base64.b64encode(buffer).decode()
            
            # Envoi au serveur
            message = {
                "type": "frame",
                "data": frame_b64,
                "config": {"confidence_threshold": 0.5}
            }
            
            await websocket.send(json.dumps(message))
            
            # RÃ©ception rÃ©sultat
            response = await websocket.recv()
            result = json.loads(response)
            
            if result['type'] == 'detection':
                objects = result['result']['total_objects']
                lost = result['result']['lost_objects']
                print(f"ğŸ” {objects} objets, {lost} perdus")
            
            elif result['type'] == 'alert':
                print(f"ğŸš¨ ALERTE: {result['alert']['message']}")

# ExÃ©cution
asyncio.run(stream_webcam())
```

## ğŸ¤– Gestion des ModÃ¨les

### ModÃ¨les SupportÃ©s

Le service supporte plusieurs modÃ¨les optimisÃ©s pour diffÃ©rents cas d'usage :

| ModÃ¨le | Description | Performance | Vitesse | Usage |
|--------|-------------|-------------|---------|--------|
| `stable_epoch_30` | **Champion** - ModÃ¨le principal | ğŸŸ¢ Haute | ğŸŸ¡ Moyenne | DÃ©tection gÃ©nÃ©rale |
| `extended_28_classes` | ModÃ¨le Ã©tendu 28 classes | ğŸŸ¢ TrÃ¨s haute | ğŸŸ¡ Moyenne | Classification dÃ©taillÃ©e |
| `fast_stream` | OptimisÃ© temps rÃ©el | ğŸŸ¡ Moyenne | ğŸŸ¢ TrÃ¨s rapide | Streaming |

### Ajout de Vos ModÃ¨les

1. **Placez vos fichiers `.pth`** dans `storage/models/`
2. **Modifiez la configuration** dans `app/config/config.py`
3. **RedÃ©marrez le service**

```python
# Exemple d'ajout dans config.py
MODEL_CONFIGS = {
    'mon_modele': {
        'file': 'mon_modele.pth',
        'description': 'Mon modÃ¨le personnalisÃ©',
        'performance': 'high',
        'speed': 'fast'
    }
}
```

## ğŸ“Š Logique MÃ©tier - Objets Perdus

### Ã‰tats d'un Objet

```mermaid
graph LR
    A[ğŸŸ¢ Normal] --> B[ğŸŸ¡ Surveillance]
    B --> C[ğŸŸ  Suspect]
    C --> D[ğŸ”´ Perdu]
    D --> E[ğŸ”´ Critique]
    D --> F[âœ… RÃ©solu]
    C --> F
```

| Ã‰tat | Conditions | DurÃ©e | Actions |
|------|------------|-------|---------|
| **ğŸŸ¢ Normal** | PropriÃ©taire prÃ©sent | - | Surveillance passive |
| **ğŸŸ¡ Surveillance** | Immobile 30s | 30s | Surveillance renforcÃ©e |
| **ğŸŸ  Suspect** | Pas de propriÃ©taire 30s | 30s-5min | Alerte prÃ©ventive |
| **ğŸ”´ Perdu** | AbandonnÃ© > 5min | 5-30min | Alerte sÃ©curitÃ© |
| **ğŸ”´ Critique** | AbandonnÃ© > 30min | 30min+ | Intervention prioritaire |

### ParamÃ¨tres Configurables

```bash
# .env
SUSPECT_THRESHOLD_SECONDS=30      # Temps avant suspect
LOST_THRESHOLD_SECONDS=300        # Temps avant perdu (5min)
CRITICAL_THRESHOLD_SECONDS=1800   # Temps avant critique (30min)
OWNER_PROXIMITY_METERS=2.5        # Distance propriÃ©taire (mÃ¨tres)
```

## ğŸ› ï¸ Configuration AvancÃ©e

### Variables d'Environnement

```bash
# Performance
USE_GPU=True                    # Utiliser GPU si disponible
BATCH_SIZE=4                   # Taille batch traitement
MAX_MEMORY_USAGE=0.8           # Limite mÃ©moire GPU

# Streaming
MAX_CONNECTIONS=10             # Connexions WebSocket max
STREAM_FPS=15                  # FPS streaming
BUFFER_SIZE=30                 # Taille buffer frames

# Cache
CACHE_TTL=3600                 # TTL cache (secondes)
MAX_CACHE_SIZE=100             # Taille max cache

# SÃ©curitÃ© (production)
SECRET_KEY=your-secret-key
ACCESS_TOKEN_EXPIRE_MINUTES=30
```

### Configuration ModÃ¨les

```python
# app/config/config.py
MODEL_CONFIG = {
    'num_classes': 28,
    'image_size': (320, 320),
    'confidence_threshold': 0.5,
    'nms_threshold': 0.5,
    'classes': [
        'person', 'backpack', 'suitcase', 'handbag', 'tie',
        'umbrella', 'hair drier', 'toothbrush', 'cell phone',
        'laptop', 'keyboard', 'mouse', 'remote', 'tv',
        'clock', 'microwave', 'bottle', 'cup', 'bowl',
        'knife', 'spoon', 'fork', 'wine glass', 'refrigerator',
        'scissors', 'book', 'vase', 'chair'
    ]
}
```

## ğŸ“ˆ Monitoring et Analytics

### MÃ©triques Disponibles

- **Performance** : Temps de traitement, FPS, usage mÃ©moire
- **DÃ©tections** : Nombre d'objets, types, confiance
- **Alertes** : FrÃ©quence, types, rÃ©solutions
- **SystÃ¨me** : Charge CPU/GPU, connexions actives

### Endpoints de Monitoring

```bash
GET /health              # SantÃ© systÃ¨me
GET /stats               # Statistiques globales
GET /api/v1/models/health # SantÃ© modÃ¨les
GET /api/v1/stream/status # Ã‰tat streaming
```

### IntÃ©gration Prometheus

```yaml
# docker-compose.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    profiles:
      - monitoring
```

## ğŸ§ª Tests

### ExÃ©cution des Tests

```bash
# Tests complets
python -m pytest tests/ -v

# Tests spÃ©cifiques
python -m pytest tests/test_api.py -v

# Tests avec couverture
pip install pytest-cov
python -m pytest tests/ --cov=app --cov-report=html
```

### Tests d'IntÃ©gration

```bash
# DÃ©marrer le service de test
python scripts/start_service.py --port 8001 &

# ExÃ©cuter les tests d'intÃ©gration
python tests/integration_tests.py

# ArrÃªter le service de test
pkill -f "uvicorn.*8001"
```

## ğŸš€ DÃ©ploiement Production

### Docker Production

```bash
# Build image de production
docker build -t ai-service:prod .

# DÃ©ploiement avec monitoring
docker-compose --profile production --profile monitoring up -d
```

### Configuration Production

```bash
# .env.production
DEBUG=False
USE_GPU=True
WORKERS=4
LOG_LEVEL=WARNING

# SÃ©curitÃ©
SECRET_KEY=your-production-secret
CORS_ORIGINS=["https://yourapp.com"]

# Base de donnÃ©es
DATABASE_URL=postgresql://user:pass@db:5432/ai_service

# Cache Redis
REDIS_URL=redis://redis:6379
```

### Nginx Reverse Proxy

```nginx
# nginx/nginx.conf
upstream ai_service {
    server ai-service:8000;
}

server {
    listen 80;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://ai_service;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    location /ws/ {
        proxy_pass http://ai_service;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes Courants

**âŒ ModÃ¨les non trouvÃ©s**
```bash
# Solution
mkdir -p storage/models
# Placez vos fichiers .pth dans ce rÃ©pertoire
```

**âŒ Erreur CUDA**
```bash
# VÃ©rifiez GPU
python -c "import torch; print(torch.cuda.is_available())"

# Forcer CPU
export USE_GPU=False
```

**âŒ Port dÃ©jÃ  utilisÃ©**
```bash
# Changer le port
python scripts/start_service.py --port 8001
```

**âŒ MÃ©moire insuffisante**
```bash
# RÃ©duire batch size
export BATCH_SIZE=1
export MAX_CONNECTIONS=5
```

### Logs de Debug

```bash
# Logs dÃ©taillÃ©s
export LOG_LEVEL=DEBUG
python scripts/start_service.py

# Logs dans fichier
tail -f logs/ai_service.log
```

## ğŸ¤ Contribution

### Structure des Commits

```bash
feat: nouvelle fonctionnalitÃ©
fix: correction de bug
docs: documentation
style: formatage code
refactor: refactoring
test: ajout tests
chore: maintenance
```

### DÃ©veloppement

```bash
# Setup environnement dev
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

pip install -r requirements.txt
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Tests avant commit
python -m pytest tests/
python -m black app/
python -m flake8 app/
```

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- **ğŸ“§ Email** : support@yourcompany.com
- **ğŸ’¬ Discord** : [Serveur Discord](https://discord.gg/yourserver)
- **ğŸ“– Documentation** : [Wiki](https://github.com/yourrepo/wiki)
- **ğŸ› Issues** : [GitHub Issues](https://github.com/yourrepo/issues)

## ğŸ”„ Versions

- **v1.0.0** - Version initiale avec dÃ©tection d'images et streaming
- **v1.1.0** - Ajout traitement vidÃ©o et analytics
- **v1.2.0** - Optimisations performance et monitoring

---

**ğŸ¯ Fait avec â¤ï¸ pour la sÃ©curitÃ© et l'innovation**